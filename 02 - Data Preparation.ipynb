{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving data from client sources\n",
    "\n",
    "WIP - probably SQL\n",
    "\n",
    "# Defining the scope of the problem\n",
    "## Regression or classification \n",
    "\n",
    "If the client has a continuous variable as an output, does it make sense to convert it into categorical variables? Think about the consequences your decision may have.\n",
    "\n",
    "## Use of additional datasets\n",
    "Your dataset isn’t restricted to the information provided by the client - it’s always possible to get more data from various sources. A list of open source datasets is available in the ‘Resources’ section of the playbook.\n",
    "\n",
    "# Getting an overview of your dataset\n",
    "## Using Pandas *\n",
    "Our default methods are:\n",
    "\n",
    "* Data.head\n",
    "* Data.describe\n",
    "* Whatever that Seaborn method is for generating lots of correlations at once\n",
    "\n",
    "\\* Bonus: why the hell is Pandas called Pandas?\n",
    "> The library’s name derives from panel data, a common term for multidimensional data sets encountered in statistics and econometrics.\n",
    "\n",
    "Thanks [@triketora](https://www.quora.com/Why-is-the-pandas-Python-library-named-pandas).\n",
    "\n",
    "## Using the command line\n",
    "Speed up early data analysis by using command line tools like [csvkit](http://csvkit.readthedocs.org/) and [data_hacks](https://github.com/bitly/data_hacks). \n",
    "\n",
    "We covered the basics in the [Client Relations playbook](http://nbviewer.jupyter.org/github/theianchan/elephant-playbooks/blob/master/01%20-%20Client%20Relations.ipynb), but let's take it a step further here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. county\n",
      "\t<type 'unicode'>\n",
      "\tNulls: False\n",
      "\tUnique values: 35\n",
      "\t5 most frequent values:\n",
      "\t\tDOUGLAS:\t760\n",
      "\t\tDAKOTA:\t42\n",
      "\t\tCASS:\t37\n",
      "\t\tHALL:\t23\n",
      "\t\tLANCASTER:\t18\n",
      "\tMax length: 10\n",
      "  2. acquisition_cost\n",
      "\t<type 'float'>\n",
      "\tNulls: False\n",
      "\tMin: 0.0\n",
      "\tMax: 412000.0\n",
      "\tSum: 5430787.55\n",
      "\tMean: 5242.07292471\n",
      "\tMedian: 6000.0\n",
      "\tStandard Deviation: 13361.6250351\n",
      "\tUnique values: 75\n",
      "\t5 most frequent values:\n",
      "\t\t6800.0:\t304\n",
      "\t\t10747.0:\t195\n",
      "\t\t6000.0:\t105\n",
      "\t\t499.0:\t98\n",
      "\t\t0.0:\t81\n",
      "  3. ship_date\n",
      "\t<type 'datetime.date'>\n",
      "\tNulls: False\n",
      "\tMin: 2006-03-07\n",
      "\tMax: 2014-01-30\n",
      "\tUnique values: 84\n",
      "\t5 most frequent values:\n",
      "\t\t2013-04-25:\t495\n",
      "\t\t2013-04-26:\t160\n",
      "\t\t2008-05-20:\t28\n",
      "\t\t2012-04-16:\t26\n",
      "\t\t2006-11-17:\t20\n",
      "\n",
      "Row count: 1036\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd csvkit_tutorial\n",
    "\n",
    "# Get summary statistics for a few columns in data.csv\n",
    "csvcut -c county,acquisition_cost,ship_date data.csv | csvstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|------------+--------------------------------+-------------|\n",
      "|  county    | item_name                      | total_cost  |\n",
      "|------------+--------------------------------+-------------|\n",
      "|  LANCASTER | MINE RESISTANT VEHICLE         | 412000      |\n",
      "|  LANCASTER | IMAGE INTENSIFIER,NIGHT VISION | 6800        |\n",
      "|  LANCASTER | IMAGE INTENSIFIER,NIGHT VISION | 6800        |\n",
      "|  LANCASTER | IMAGE INTENSIFIER,NIGHT VISION | 6800        |\n",
      "|  LANCASTER | IMAGE INTENSIFIER,NIGHT VISION | 6800        |\n",
      "|  LANCASTER | RIFLE,5.56 MILLIMETER          | 120         |\n",
      "|  LANCASTER | RIFLE,5.56 MILLIMETER          | 120         |\n",
      "|  LANCASTER | RIFLE,5.56 MILLIMETER          | 120         |\n",
      "|  LANCASTER | RIFLE,5.56 MILLIMETER          | 120         |\n",
      "|  LANCASTER | RIFLE,5.56 MILLIMETER          | 120         |\n",
      "|  LANCASTER | RIFLE,5.56 MILLIMETER          | 120         |\n",
      "|  LANCASTER | RIFLE,5.56 MILLIMETER          | 120         |\n",
      "|  LANCASTER | RIFLE,5.56 MILLIMETER          | 120         |\n",
      "|  LANCASTER | RIFLE,5.56 MILLIMETER          | 120         |\n",
      "|  LANCASTER | RIFLE,5.56 MILLIMETER          | 120         |\n",
      "|  LANCASTER | LIGHT ARMORED VEHICLE          | 0           |\n",
      "|  LANCASTER | LIGHT ARMORED VEHICLE          | 0           |\n",
      "|  LANCASTER | LIGHT ARMORED VEHICLE          | 0           |\n",
      "|------------+--------------------------------+-------------|\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd csvkit_tutorial\n",
    "\n",
    "# For just these three columns, find values in column 'county' that match LANCASTER and sort by total_cost\n",
    "csvcut -c county,item_name,total_cost data.csv | csvgrep -c county -m LANCASTER | csvsort -c total_cost -r | csvlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# NumSamples = 1036; Min = 0.00; Max = 11250.00\n",
      "# 4 values outside of min/max\n",
      "# Mean = 5242.072925; Variance = 178533023.577992; SD = 13361.625035; Median 6000.000000\n",
      "# each ∎ represents a count of 5\n",
      "    0.0000 -  1125.0000 [   419]: ∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎ (40.44%)\n",
      " 1125.0000 -  2250.0000 [     3]:  (0.29%)\n",
      " 2250.0000 -  3375.0000 [     1]:  (0.10%)\n",
      " 3375.0000 -  4500.0000 [     0]:  (0.00%)\n",
      " 4500.0000 -  5625.0000 [     0]:  (0.00%)\n",
      " 5625.0000 -  6750.0000 [   105]: ∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎ (10.14%)\n",
      " 6750.0000 -  7875.0000 [   305]: ∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎ (29.44%)\n",
      " 7875.0000 -  9000.0000 [     3]:  (0.29%)\n",
      " 9000.0000 - 10125.0000 [     1]:  (0.10%)\n",
      "10125.0000 - 11250.0000 [   195]: ∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎ (18.82%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:failed 'acquisition_cost\\n'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/histogram.py\", line 95, in load_stream\n",
      "    yield DataPoint(Decimal(clean_line), 1)\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/decimal.py\", line 548, in __new__\n",
      "    \"Invalid literal for Decimal: %r\" % value)\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/decimal.py\", line 3872, in _raise_error\n",
      "    raise error(explanation)\n",
      "InvalidOperation: Invalid literal for Decimal: 'acquisition_cost'\n",
      "invalid line 'acquisition_cost\\n'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd csvkit_tutorial\n",
    "\n",
    "# This uses data_hacks - histogram.py prints out the world's ugliest histogram \n",
    "# right in the command line (only works with continuous vars)\n",
    "\n",
    "csvcut -c 8 data.csv | histogram.py --percentage --max=11250 --min=0\n",
    "\n",
    "# Yes, there is an error because csvcut outputs the header as well\n",
    "# I haven't figured out a way to exclude it yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also commands for converting your data to/from SQL/JSON. [Check out the docs](http://csvkit.readthedocs.io/en/540/tutorial/3_power_tools.html).\n",
    "\n",
    "# Notebook setup\n",
    "\n",
    "jupyterhub - multi-user notebook environment \n",
    "\n",
    "# Fixing data formats\n",
    "## Date and time data\n",
    "\n",
    "WIP\n",
    "\n",
    "# Dealing with erroneous values\n",
    "## Standardizing categories\n",
    "\n",
    "WIP\n",
    "\n",
    "## Typos\n",
    "\n",
    "WIP\n",
    "\n",
    "# Dealing with outliers\n",
    "\n",
    "WIP\n",
    "\n",
    "# Dealing with missing values\n",
    "## MCAR, MAR, NMAR/MNAR\n",
    "\n",
    "WIP\n",
    "\n",
    "## Dropping \n",
    "\n",
    "WIP\n",
    "\n",
    "## Single imputation\n",
    "\n",
    "This section technically includes the use of mean and simple regression prediction, but both those methods are absolutely the wrong way to deal with missing values so I will omit them.\n",
    "\n",
    "## Regression prediction + error\n",
    "\n",
    "Best possible using Python.\n",
    "\n",
    "## Hot-decking\n",
    "\n",
    "WIP\n",
    "\n",
    "## Predictive mean-matching\n",
    "\n",
    "WIP\n",
    "\n",
    "## Multiple imputation\n",
    "\n",
    "Requires R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "## Reading\n",
    "### Articles\n",
    "\n",
    "1. Julia Evans' writing on Machine Learning - [http://jvns.ca/blog/categories/machinelearning/](http://jvns.ca/blog/categories/machinelearning/)\n",
    "\n",
    "### Books\n",
    "\n",
    "1. Data Science at the Command Line - [http://shop.oreilly.com/product/0636920032823.do](http://shop.oreilly.com/product/0636920032823.do)\n",
    "\n",
    "## Datasets\n",
    "### Hosted by government institutions\n",
    "\n",
    "1. NYC Open Data - [https://nycopendata.socrata.com/](https://nycopendata.socrata.com/)\n",
    "2. DC Open Data Catalog - [http://data.dc.gov/](http://data.dc.gov/)\n",
    "3. OpenDataDC - [http://www.opendatadc.org/](http://www.opendatadc.org/)\n",
    "4. DataLA - [https://data.lacity.org/](https://data.lacity.org/)\n",
    "5. data.gov - [https://www.data.gov/](https://www.data.gov/)\n",
    "6. Project Open Data Dashboard - [http://data.civicagency.org/](http://data.civicagency.org/)\n",
    "7. data.gov.uk - [http://data.gov.uk/](http://data.gov.uk/)\n",
    "8. US Census Bureau - [http://www.census.gov/](http://www.census.gov/)\n",
    "9. World Bank Open Data - [http://data.worldbank.org/](http://data.worldbank.org/)\n",
    "10. Humanitarian Data Exchange - [http://docs.hdx.rwlabs.org/](http://docs.hdx.rwlabs.org/)\n",
    "11. Sunlight Foundation - [http://sunlightfoundation.com/api/](http://sunlightfoundation.com/api/)\n",
    "12. ProPublica Data Store - [https://projects.propublica.org/data-store/](https://projects.propublica.org/data-store/)\n",
    "\n",
    "### Hosted by academic institutions\n",
    "\n",
    "1. UC Irvine Machine Learning Repository (Datasets specifically designed for machine learning) - [http://archive.ics.uci.edu/ml/](http://archive.ics.uci.edu/ml/)\n",
    "2. Stanford Large Network Dataset Collection - [http://snap.stanford.edu/data/](http://snap.stanford.edu/data/)\n",
    "3. Inter-university Consortium for Political and Social Research - [http://www.icpsr.umich.edu/](http://www.icpsr.umich.edu/)\n",
    "4. Pittsburgh Science of Learning Center's DataShop - [http://www.learnlab.org/technologies/datashop/](http://www.learnlab.org/technologies/datashop/)\n",
    "5. Academic Torrents - [http://academictorrents.com/](http://academictorrents.com/)\n",
    "\n",
    "### Hosted by private companies\n",
    "\n",
    "1. Quandl (Over 10 million financial, economic, and social datasets) - [https://www.quandl.com/](https://www.quandl.com/)\n",
    "2. Amazon Web Services Public Data Sets - [http://aws.amazon.com/datasets/](http://aws.amazon.com/datasets/)\n",
    "3. Kaggle (Provides datasets with their challenges, but each competition has its own rules as to whether the data can be used outside of the scope of the competition) - [http://www.kaggle.com/](http://www.kaggle.com/)\n",
    "\n",
    "### Other\n",
    "\n",
    "1. Rdatasets - [http://vincentarelbundock.github.io/Rdatasets/](http://vincentarelbundock.github.io/Rdatasets/)\n",
    "2. RDataMining.com - [http://www.rdatamining.com/resources/data](http://www.rdatamining.com/resources/data)\n",
    "3. KDnuggets - [http://www.kdnuggets.com/datasets/index.html](http://www.kdnuggets.com/datasets/index.html)\n",
    "4. inside-R - [http://www.inside-r.org/howto/finding-data-internet](http://www.inside-r.org/howto/finding-data-internet)\n",
    "5. 100+ Interesting Data Sets for Statistics - [http://rs.io/2014/05/29/list-of-data-sets.html](http://rs.io/2014/05/29/list-of-data-sets.html)\n",
    "6. 20 Free Big Data Sources - [http://smartdatacollective.com/bernardmarr/235366/big-data-20-free-big-data-sources-everyone-should-know](http://smartdatacollective.com/bernardmarr/235366/big-data-20-free-big-data-sources-everyone-should-know)\n",
    "7. FiveThirtyEight - [https://github.com/fivethirtyeight/data](https://github.com/fivethirtyeight/data)\n",
    "8. Donors Choose - [http://data.donorschoose.org/open-data/overview/](http://data.donorschoose.org/open-data/overview/)\n",
    "9. 200,000+ Jeopardy questions - [http://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/](http://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/)\n",
    "\n",
    "## APIs\n",
    "\n",
    "1. Apigee (Explore dozens of popular APIs) - [https://apigee.com/providers](https://apigee.com/providers)\n",
    "2. Python APIs (Python wrappers for many APIs) - [http://www.pythonforbeginners.com/api/list-of-python-apis](http://www.pythonforbeginners.com/api/list-of-python-apis)\n",
    "\n",
    "## Tools\n",
    "\n",
    "1. CrowdFlower - [http://crowdflower.com/](http://crowdflower.com/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
